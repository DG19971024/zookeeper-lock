## zookeeper-lock

### 利用Zookeeper实现分布式锁
使用该分布式锁，去简单的模拟一个秒杀场景下的减商品库存

**利用的两个Zookeeper特性**

（1）临时有序节点：保证了即使客户端发生异常没有删除节点，该节点也会自动被删除。而且有序节点可以将所有操作变成串行操作。

（2）事件监听与回调机制：Zookeeper客户端与服务端实现了事件监听与回调，该机制非常重要，他可以保证服务端的节点发生改变时，客户端可以感知并作出相应的动作。

**实现锁的思路原理**

（1）以节点序号判断是否获取到锁，每个线程在创建锁时，都会在Zookeeper服务端创建一个临时有序节点，依据Zookeeper有序节点的性质，
每一个节点的序号都是有序依次递增，所以，我们每创建一个节点，都可以监控前一个序号的节点是否被删除（还有种情况，就是监控时该节点已经删除了，也就是节点不存在），
如果已被删除那么就表示当前节点是头节点，可以获取锁，如果没有被删除，则表示不能获取锁

（2）临时有序节点，临时节点可以保证及时客户端由于某种原因没有释放锁（删除节点），服务端也会自动的删除该节点，可以避免死锁

（3）如果当前线程没有获取到锁，则需要进入阻塞或者超时阻塞状态，可以通过JDK自带的一些线程同步类实现，比如通过CountDownLatch

（4）获取到锁后（也即是监听到前一个节点被删除的时间、或者判断到该节点已经不存在了），通过Watcher机制，解除主线程的阻塞，获取到锁。

**初版实现ReentrantLockZk**
初步实现问题比较大，仅作为一个测试demo，实验自己的思路能否实现加锁与释放。代码缺陷如下：

（1）异常处理，这里的异常情况确实比较多，尤其是有可能发生客户端与服务端断开连接的情况，具体应该怎么处理就必须要详细思考，每一个异常分支都要进行相应的处理，如果获取锁方法报了异常，是否要进行重试，重试几次，如果确实无法获取锁的话主线程的业务代码是否继续执行，都是需要考虑的。

（2）可能会发生事件丢失的情况，也就是监控的某个节点发生了节点删除事件，但是客户端由于某种原因没有收到该事件的通知，就可能会导致死锁问题。

（3）一旦请求压力过大，瞬间数万请求（也就是数万个子节点）甚至数十万打入Zookeeper下：首先要面临的问题就是节点队列过长的问题，如果一个节点的从创建到删除操作需要1秒的时间，那么数万个节点可以想象，对于处于后面的节点等待时间是非常恐怖的，根本等待不到获取锁。另一个问题就是，数万个节点的节点名数据都是要缓存一份到本地的，可能会导致出现内存溢出。这个可以通过一些限流手段解决，首先可以想到加一个消息中间件比如RabbitMQ或者Kafka去做一个削峰限流。

或者，利用Zookeeper有序节点的特性，当前节点的序号-1就是上一个节点的序号，所以只需要监控上一个节点，就可以无需获取所有的子节点序列集合。

（4）没有实现可重入锁，这个比较简单，模仿一下JDK中ReentrantLock锁的实现即可，非常简单。

（5）需要提供几个有参构造方法，可以手动指定父节点、子节点的路径名字，数据内容可选。目前父节点和子节点的路径名称都是默认的，这样会造成的问题比较大（不同业务代码，却被同一把锁加锁）。

（6）获取锁超时问题，没有进行获取锁超时情况下的处理。加锁的方法最好设置一个超时参数。这个实现比较简单，可以直接通过countDownLatch.await()方法来实现，加超时参数即可，该方法有一个重载版本，专门用于进行超时处理

public boolean await(long timeout, TimeUnit unit)

**代码改版ReentrantLockZk2**
这一版代码主要是针对初版代码缺陷中的第（3）条进行的优化改进。

**代码改版ReentrantLockZk3**
这一版代码主要是针对初版代码缺陷中的第（3）（5）条进行的优化改进，同时不再使用异步的exists方法来监控节点是否被删除，删除LockCallBack回调类，使代码更加简洁

**代码改版ReentrantLockZk4**
这一版代码主要是针对初版代码缺陷中的第（3）（5）（6）条进行的优化改进，提供了超时参数的重载版本。